{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, f1_score, balanced_accuracy_score #classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from pytrie import StringTrie\n",
    "from collections import Counter\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_imp(lm_coef, X,y):\n",
    "    feature_importance = lm_coef\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "    featfig = plt.figure()\n",
    "    print(pos)\n",
    "    print(feature_importance[sorted_idx])\n",
    "    print(np.array(X.columns)[sorted_idx])\n",
    "    featax = featfig.add_subplot(1, 1, 1)\n",
    "    featax.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "    featax.set_yticks(pos)\n",
    "    featax.set_yticklabels(np.array(X.columns)[sorted_idx], fontsize=8)\n",
    "    featax.set_xlabel('Relative Feature Importance')\n",
    "    plt.tight_layout()   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_imp_df(lm_coef, X,y):\n",
    "    feature_importance = lm_coef\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "    label = np.array(X.columns)[sorted_idx]\n",
    "    value = feature_importance[sorted_idx]\n",
    "    feat_imp_df = pd.DataFrame({'feature':label,'Imp_index':value})\n",
    "    return feat_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module to do factor Analysis on the columns\n",
    "# Function: to find the Strings with first few letters e.g. 'ASE', 'Z_ASE'\n",
    "def prefixSearch(arr,prefix): \n",
    "    trie=StringTrie() \n",
    "    for key in arr: \n",
    "        trie[key] = key \n",
    "    return trie.values(prefix) \n",
    "\n",
    "# Function to calculate No of Factors based on Eigen Values\n",
    "def eigenvalues(data):\n",
    "    eigvals=np.array(data)\n",
    "    eigvals=eigvals.T\n",
    "    corrmat=np.corrcoef(eigvals)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(corrmat)\n",
    "    Count=Counter(eigenvalues>1)[1]\n",
    "    return Count,eigenvectors\n",
    "\n",
    "# Function to calculate Factor Scores\n",
    "def FacterCluster(df,rotation = 'varimax'):\n",
    "    fa = FactorAnalyzer(n_factors=eigenvalues(df)[0],rotation=rotation,method='ml',use_smc=True)\n",
    "    df1=pd.DataFrame.from_records(fa.fit_transform(df))\n",
    "    df1=pd.DataFrame(df1)\n",
    "    df1 = df1.add_prefix('Factor_')\n",
    "    df2 = pd.concat([df, df1], axis=1)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module for resampling Unbalanced data\n",
    "def up_sample_imbalanced(df,feature='lapse' ):\n",
    "    y_zero = df[df[feature]== 0]\n",
    "    y_one = df[df[feature]== 1]\n",
    "    ##Upsample the 1 cases\n",
    "    df_resampled = resample(y_one,\n",
    "                            replace=True, # sample with replacement\n",
    "                            n_samples=y_zero.shape[0])\n",
    "    ndf = pd.concat([y_zero, df_resampled]).reset_index()\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "def Logistic_Regression(X_train, X_test, y_train, y_test, mdf):\n",
    "    start = time.time()\n",
    "    print('**Logistic Regression**')\n",
    "    logmodel = LogisticRegression(random_state=0,class_weight='balanced', solver = 'saga')\n",
    "    logmodel.fit(X_train,y_train)\n",
    "    predictions = logmodel.predict(X_test)\n",
    "    Train_Accuracy = accuracy_score(y_train, logmodel.predict(X_train))\n",
    "    Test_Accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Confusion matrix: \\n \", confusion_matrix(y_test, predictions))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions)\n",
    "    aucx = metrics.auc(fpr, tpr)\n",
    "    f1x = metrics.f1_score(y_test, predictions)\n",
    "    bal_f1scr = metrics.balanced_accuracy_score(y_test, predictions)\n",
    "    accuracyx = metrics.accuracy_score(y_test, predictions)\n",
    "    pred_prob = pd.concat([pd.DataFrame(logmodel.predict_proba(mdf[X_train.columns])).reset_index(drop=True),mdf[pd.DataFrame(y_train).columns]], axis=1)\n",
    "    pred_prob = pd.concat([pred_prob.reset_index(drop=True),pd.DataFrame(logmodel.predict(mdf[X_train.columns]))], axis=1)\n",
    "    pred_prob.columns = ['pred_prob_0','pred_prob_1', 'Actual', 'predicted']\n",
    "    var_imp = var_imp_df(abs(logmodel.coef_[0]), mdf[X_train.columns],mdf[pd.DataFrame(y_train).columns])\n",
    "    model_metrics = {'Model':['Logistic_Regression'],'Accuracy':[accuracyx],\n",
    "                     'AUC': [aucx], 'F1_Score':[f1x], 'Balanced_F1_Score':[bal_f1scr],\n",
    "                    'Train_Accuracy':[Train_Accuracy], 'Test_Accuracy':[Test_Accuracy],\n",
    "                     'TimeTaken':[time.time()-start]}\n",
    "    moddf = pd.DataFrame(model_metrics, columns=['Model','Accuracy','AUC','F1_Score',\n",
    "                                                 'Balanced_F1_Score','Train_Accuracy',\n",
    "                                                 'Test_Accuracy','TimeTaken'])\n",
    "    return moddf, pred_prob, var_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_Regression_cv(X_train, X_test, y_train, y_test, mdf):\n",
    "    start = time.time()\n",
    "    print('**Logistic Regression Cross Validation**')\n",
    "    logmodel = LogisticRegressionCV(cv=5,random_state=0,class_weight='balanced')\n",
    "    logmodel.fit(X_train,y_train)\n",
    "    predictions = logmodel.predict(X_test)\n",
    "    Train_Accuracy = accuracy_score(y_train, logmodel.predict(X_train))\n",
    "    Test_Accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Confusion matrix: \\n \", confusion_matrix(y_test, predictions))\n",
    "    #print(\"Classification Report: \\n \", classification_report(y_test, predictions))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions)\n",
    "    aucx = metrics.auc(fpr, tpr)\n",
    "    f1x = metrics.f1_score(y_test, predictions)\n",
    "    bal_f1scr = metrics.balanced_accuracy_score(y_test, predictions)\n",
    "    accuracyx = metrics.accuracy_score(y_test, predictions)\n",
    "    pred_prob = pd.concat([pd.DataFrame(logmodel.predict_proba(mdf[X_train.columns])).reset_index(drop=True),mdf[pd.DataFrame(y_train).columns]], axis=1)\n",
    "    pred_prob = pd.concat([pred_prob.reset_index(drop=True),pd.DataFrame(logmodel.predict(mdf[X_train.columns]))], axis=1)\n",
    "    pred_prob.columns = ['pred_prob_0','pred_prob_1', 'Actual', 'predicted']\n",
    "    var_imp = var_imp_df(abs(logmodel.coef_[0]), mdf[X_train.columns],mdf[pd.DataFrame(y_train).columns])\n",
    "    model_metrics = {'Model':['Logistic_Regression_CV'],'Accuracy':[accuracyx],\n",
    "                     'AUC': [aucx], 'F1_Score':[f1x],'Balanced_F1_Score':[bal_f1scr],\n",
    "                    'Train_Accuracy':[Train_Accuracy], 'Test_Accuracy':[Test_Accuracy],\n",
    "                    'TimeTaken':[time.time()-start]}\n",
    "    moddf = pd.DataFrame(model_metrics, columns=['Model','Accuracy','AUC',\n",
    "                                                 'F1_Score','Balanced_F1_Score',\n",
    "                                                 'Train_Accuracy','Test_Accuracy','TimeTaken'])\n",
    "    return moddf, pred_prob,var_imp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "def random_forest(X_train, X_test, y_train, y_test, mdf):\n",
    "    start = time.time()\n",
    "    print('**Random Forest**')\n",
    "    ## Configuring parameters and values for searched\n",
    "    tuned_parameters = [{'max_depth': [10, 15],\n",
    "                         'n_estimators': [10,20],\n",
    "                         'max_features': ['sqrt', 'auto', 'log2']}]\n",
    "    ## Initializing the RF classifier\n",
    "    radm_clf = RandomForestClassifier()\n",
    "    ## Configuring search with the tunable parameters\n",
    "    clf = GridSearchCV(radm_clf,\n",
    "                       tuned_parameters,\n",
    "                       cv=15,\n",
    "                       scoring='roc_auc')\n",
    "    ## Fitting the training set\n",
    "    clf.fit(X_train, y_train)\n",
    "    m = clf.best_params_\n",
    "    # Using best parameters from grid search\n",
    "    clf = RandomForestClassifier(max_depth=m['max_depth'], n_estimators=m['n_estimators'],\n",
    "                                 max_features = m['max_features'],random_state=101)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    Train_Accuracy = accuracy_score(y_train, clf.predict(X_train))\n",
    "    Test_Accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Confusion matrix: \\n \", confusion_matrix(y_test, predictions))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions)\n",
    "    aucx = metrics.auc(fpr, tpr)\n",
    "    f1x = metrics.f1_score(y_test, predictions)\n",
    "    bal_f1scr = metrics.balanced_accuracy_score(y_test, predictions)\n",
    "    accuracyx = metrics.accuracy_score(y_test, predictions)\n",
    "    pred_prob = pd.concat([pd.DataFrame(clf.predict_proba(mdf[X_train.columns])).reset_index(drop=True),mdf[pd.DataFrame(y_train).columns]], axis=1)\n",
    "    pred_prob = pd.concat([pred_prob.reset_index(drop=True),pd.DataFrame(clf.predict(mdf[X_train.columns]))], axis=1)\n",
    "    pred_prob.columns = ['pred_prob_0','pred_prob_1', 'Actual', 'predicted']\n",
    "    var_imp = var_imp_df(abs(clf.feature_importances_), mdf[X_train.columns],mdf[pd.DataFrame(y_train).columns])\n",
    "    model_metrics = {'Model':['random_forest_clf'],'Accuracy':[accuracyx],\n",
    "                     'AUC': [aucx], 'F1_Score':[f1x],'Balanced_F1_Score':[bal_f1scr],\n",
    "                    'Train_Accuracy':[Train_Accuracy], 'Test_Accuracy':[Test_Accuracy],\n",
    "                    'TimeTaken':[time.time()-start]}\n",
    "    moddf = pd.DataFrame(model_metrics, columns=['Model','Accuracy','AUC',\n",
    "                                                 'F1_Score','Balanced_F1_Score',\n",
    "                                                 'Train_Accuracy','Test_Accuracy','TimeTaken'])\n",
    "    return moddf, pred_prob, var_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "def gradient_boost(X_train, X_test, y_train, y_test, mdf):\n",
    "    start = time.time()\n",
    "    print('**Gradient Boosting Classifier**')\n",
    "    gboost_clf = GradientBoostingClassifier( n_estimators=500, max_depth=10)\n",
    "    gboost_clf.fit(X_train, y_train)\n",
    "    predictions = gboost_clf.predict(X_test)\n",
    "    Train_Accuracy = accuracy_score(y_train, gboost_clf.predict(X_train))\n",
    "    Test_Accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Confusion matrix: \\n \", confusion_matrix(y_test, predictions))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions)\n",
    "    aucx = metrics.auc(fpr, tpr)\n",
    "    f1x = metrics.f1_score(y_test, predictions)\n",
    "    bal_f1scr = metrics.balanced_accuracy_score(y_test, predictions)\n",
    "    accuracyx = metrics.accuracy_score(y_test, predictions)\n",
    "    pred_prob = pd.concat([pd.DataFrame(gboost_clf.predict_proba(mdf[X_train.columns])).reset_index(drop=True),mdf[pd.DataFrame(y_train).columns]], axis=1)\n",
    "    pred_prob = pd.concat([pred_prob.reset_index(drop=True),pd.DataFrame(gboost_clf.predict(mdf[X_train.columns]))], axis=1)\n",
    "    pred_prob.columns = ['pred_prob_0','pred_prob_1', 'Actual', 'predicted']\n",
    "    var_imp = var_imp_df(abs(gboost_clf.feature_importances_), mdf[X_train.columns],mdf[pd.DataFrame(y_train).columns])\n",
    "    model_metrics = {'Model':['gradient_boost_clf'],'Accuracy':[accuracyx],\n",
    "                     'AUC': [aucx], 'F1_Score':[f1x],'Balanced_F1_Score':[bal_f1scr],\n",
    "                    'Train_Accuracy':[Train_Accuracy], 'Test_Accuracy':[Test_Accuracy],\n",
    "                    'TimeTaken':[time.time()-start]}\n",
    "    moddf = pd.DataFrame(model_metrics, columns=['Model','Accuracy','AUC',\n",
    "                                                 'F1_Score','Balanced_F1_Score',\n",
    "                                                 'Train_Accuracy','Test_Accuracy','TimeTaken'])\n",
    "    return moddf, pred_prob, var_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "def decision_tree_clf(X_train, X_test, y_train, y_test, mdf):\n",
    "    start = time.time()\n",
    "    print('**Decision Tree Classification**')\n",
    "    # Grid Search for best Parameters\n",
    "    tuned_parameters = [{'criterion': ['gini','entropy'], \n",
    "                         'max_depth': range(2,10), \n",
    "                         'max_features':[None,'auto', 'sqrt', 'log2']}]\n",
    "    clf_tree = DecisionTreeClassifier()\n",
    "    clf = GridSearchCV(clf_tree,\n",
    "                   tuned_parameters,\n",
    "                   cv=10,\n",
    "                   scoring='roc_auc')\n",
    "    clf.fit(X_train, y_train)\n",
    "    m = clf.best_params_\n",
    "    # Model with best parameters\n",
    "    clf_tree = DecisionTreeClassifier(criterion = m['criterion'], \n",
    "                                      max_depth = m['max_depth'], max_features=m['max_features'])\n",
    "    clf_tree.fit( X_train, y_train )\n",
    "    predictions = clf_tree.predict(X_test)\n",
    "    Train_Accuracy = accuracy_score(y_train, clf_tree.predict(X_train))\n",
    "    Test_Accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Confusion matrix: \\n \", confusion_matrix(y_test, predictions))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions)\n",
    "    aucx = metrics.auc(fpr, tpr)\n",
    "    f1x = metrics.f1_score(y_test, predictions)\n",
    "    bal_f1scr = metrics.balanced_accuracy_score(y_test, predictions)\n",
    "    accuracyx = metrics.accuracy_score(y_test, predictions)\n",
    "    pred_prob = pd.concat([pd.DataFrame(clf_tree.predict_proba(mdf[X_train.columns])).reset_index(drop=True),mdf[pd.DataFrame(y_train).columns]], axis=1)\n",
    "    pred_prob = pd.concat([pred_prob.reset_index(drop=True),pd.DataFrame(clf_tree.predict(mdf[X_train.columns]))], axis=1)\n",
    "    pred_prob.columns = ['pred_prob_0','pred_prob_1', 'Actual', 'predicted']\n",
    "    model_metrics = {'Model':['decision_tree_clf'],'Accuracy':[accuracyx],\n",
    "                     'AUC': [aucx], 'F1_Score':[f1x],'Balanced_F1_Score':[bal_f1scr],\n",
    "                    'Train_Accuracy':[Train_Accuracy], 'Test_Accuracy':[Test_Accuracy],\n",
    "                    'TimeTaken':[time.time()-start]}\n",
    "    moddf = pd.DataFrame(model_metrics, columns=['Model','Accuracy','AUC',\n",
    "                                                 'F1_Score','Balanced_F1_Score',\n",
    "                                                 'Train_Accuracy','Test_Accuracy','TimeTaken'])\n",
    "    var_imp = var_imp_df(abs(clf_tree.feature_importances_), mdf[X_train.columns],mdf[pd.DataFrame(y_train).columns])\n",
    "    return moddf, pred_prob,var_imp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Clasifier\n",
    "def knn_clf(X_train, X_test, y_train, y_test, mdf):\n",
    "    start = time.time()\n",
    "    print('**KNN Classifier**')\n",
    "    # Find Best Parameters\n",
    "    ## Creating a dictionary with hyperparameters and possible values for searching\n",
    "    tuned_parameters = [{'n_neighbors': range(5,10),'metric': ['canberra', 'euclidean', 'minkowski']}] \n",
    "    ## Configuring grid search\n",
    "    clf = GridSearchCV(KNeighborsClassifier(),\n",
    "                       tuned_parameters,\n",
    "                       cv=10,\n",
    "                       scoring='roc_auc')\n",
    "    clf.fit(X_train, y_train )\n",
    "    m = clf.best_params_\n",
    "    # Model with best parameters\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors = m['n_neighbors'], metric = m['metric'])\n",
    "    knn_clf.fit( X_train, y_train )\n",
    "    predictions = knn_clf.predict(X_test)\n",
    "    print(\"Confusion matrix: \\n \", confusion_matrix(y_test, predictions))\n",
    "    Train_Accuracy = accuracy_score(y_train, knn_clf.predict(X_train))\n",
    "    Test_Accuracy = accuracy_score(y_test, predictions)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions)\n",
    "    aucx = metrics.auc(fpr, tpr)\n",
    "    f1x = metrics.f1_score(y_test, predictions)\n",
    "    bal_f1scr = metrics.balanced_accuracy_score(y_test, predictions)\n",
    "    accuracyx = metrics.accuracy_score(y_test, predictions)\n",
    "    pred_prob = pd.concat([pd.DataFrame(knn_clf.predict_proba(mdf[X_train.columns])).reset_index(drop=True),mdf[pd.DataFrame(y_train).columns]], axis=1)\n",
    "    pred_prob = pd.concat([pred_prob.reset_index(drop=True),pd.DataFrame(knn_clf.predict(mdf[X_train.columns]))], axis=1)\n",
    "    pred_prob.columns = ['pred_prob_0','pred_prob_1', 'Actual', 'predicted']\n",
    "    model_metrics = {'Model':['knn_clf'],'Accuracy':[accuracyx],\n",
    "                     'AUC': [aucx], 'F1_Score':[f1x],'Balanced_F1_Score':[bal_f1scr],\n",
    "                    'Train_Accuracy':[Train_Accuracy], 'Test_Accuracy':[Test_Accuracy],\n",
    "                    'TimeTaken':[time.time()-start]}\n",
    "    moddf = pd.DataFrame(model_metrics, columns=['Model','Accuracy','AUC',\n",
    "                                                 'F1_Score','Balanced_F1_Score',\n",
    "                                                 'Train_Accuracy','Test_Accuracy','TimeTaken'])\n",
    "    var_imp = []\n",
    "    return moddf, pred_prob, var_imp\n",
    "    #var_imp(abs(knn_clf.feature_importances_), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSVC\n",
    "def LSVC_Clf(X_train, X_test, y_train, y_test, mdf):\n",
    "    start = time.time()\n",
    "    print('**LSVC Classifier**')\n",
    "    lsvc = LinearSVC()\n",
    "    lsvc.fit(X_train,y_train)\n",
    "    predictions = lsvc.predict(X_test)\n",
    "    Train_Accuracy = accuracy_score(y_train, lsvc.predict(X_train))\n",
    "    Test_Accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\" Confusion matrix: \\n \", confusion_matrix(y_test, predictions))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions)\n",
    "    aucx = metrics.auc(fpr, tpr)\n",
    "    f1x = metrics.f1_score(y_test, predictions)\n",
    "    bal_f1scr = metrics.balanced_accuracy_score(y_test, predictions)\n",
    "    accuracyx = metrics.accuracy_score(y_test, predictions)\n",
    "    var_imp = var_imp_df(abs(lsvc.coef_[0]), mdf[X_train.columns],mdf[pd.DataFrame(y_train).columns])\n",
    "    pred_prob = pd.concat([pd.DataFrame(lsvc.predict(mdf[X_train.columns])).reset_index(drop=True),y], axis=1)\n",
    "    pred_prob['1'] = abs(pred_prob[0]-1)\n",
    "    pred_prob['predicted'] = pred_prob['1']\n",
    "    pred_prob = pred_prob.loc[:,[0,'1','lapse','predicted']]\n",
    "    pred_prob.columns = ['pred_prob_0','pred_prob_1', 'Actual', 'predicted']\n",
    "    model_metrics = {'Model':['LSVC_Clf'],'Accuracy':[accuracyx],\n",
    "                     'AUC': [aucx], 'F1_Score':[f1x],'Balanced_F1_Score':[bal_f1scr],\n",
    "                    'Train_Accuracy':[Train_Accuracy], 'Test_Accuracy':[Test_Accuracy],\n",
    "                    'TimeTaken':[time.time()-start]}\n",
    "    moddf = pd.DataFrame(model_metrics, columns=['Model','Accuracy','AUC',\n",
    "                                                 'F1_Score','Balanced_F1_Score',\n",
    "                                                 'Train_Accuracy','Test_Accuracy','TimeTaken'])\n",
    "    return moddf, pred_prob, var_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "def SVM_clf(X_train, X_test, y_train, y_test, mdf):\n",
    "    start = time.time()\n",
    "    print('**SVM Classifier**')\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train,y_train)\n",
    "    predictions = svc.predict(X_test)\n",
    "    print(\"Train Accuracy :: \", accuracy_score(y_train, svc.predict(X_train)))\n",
    "    print(\"Test Accuracy  :: \", accuracy_score(y_test, predictions))\n",
    "    print(\" Confusion matrix: \\n \", confusion_matrix(y_test, predictions))\n",
    "    print(\" Classification Report: \\n \", classification_report(y_test, predictions))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions)\n",
    "    aucx = metrics.auc(fpr, tpr)\n",
    "    f1x = metrics.f1_score(y_test, predictions)\n",
    "    accuracyx = metrics.accuracy_score(y_test, predictions)\n",
    "    print(\"auc = \", aucx)\n",
    "    print(\"F1 Score = \", f1x)\n",
    "    print(\"Accuracy = \", accuracyx)\n",
    "    model_metrics = {'Model':['SVM_clf'],'Accuracy':[accuracyx], 'AUC': [aucx], 'F1_Score':[f1x]}\n",
    "    moddf = pd.DataFrame(model_metrics, columns=['Model','Accuracy','AUC','F1_Score'])\n",
    "    return moddf    #var_imp(abs(svc.coef_[0]), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XG Boost\n",
    "def xgb_clf(X_train, X_test, y_train, y_test, mdf):\n",
    "    start = time.time()\n",
    "    print('**XG Boost Classifier**')\n",
    "    xgbm = XGBClassifier()\n",
    "    xgbm.fit(X_train,y_train)\n",
    "    predictions = xgbm.predict(X_test)\n",
    "    Train_Accuracy = accuracy_score(y_train, xgbm.predict(X_train))\n",
    "    Test_Accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\" Confusion matrix: \\n \", confusion_matrix(y_test, predictions))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions)\n",
    "    aucx = metrics.auc(fpr, tpr)\n",
    "    f1x = metrics.f1_score(y_test, predictions)\n",
    "    bal_f1scr = metrics.balanced_accuracy_score(y_test, predictions)\n",
    "    accuracyx = metrics.accuracy_score(y_test, predictions)\n",
    "    pred_prob = pd.concat([pd.DataFrame(xgbm.predict_proba(mdf[X_train.columns])).reset_index(drop=True),mdf[pd.DataFrame(y_train).columns]], axis=1)\n",
    "    pred_prob = pd.concat([pred_prob.reset_index(drop=True),pd.DataFrame(xgbm.predict(mdf[X_train.columns]))], axis=1)\n",
    "    pred_prob.columns = ['pred_prob_0','pred_prob_1', 'Actual', 'predicted']\n",
    "    var_imp = var_imp_df(abs(xgbm.feature_importances_), mdf[X_train.columns],mdf[pd.DataFrame(y_train).columns])\n",
    "    model_metrics = {'Model':['xgb_clf'],'Accuracy':[accuracyx],\n",
    "                     'AUC': [aucx], 'F1_Score':[f1x],'Balanced_F1_Score':[bal_f1scr],\n",
    "                    'Train_Accuracy':[Train_Accuracy], 'Test_Accuracy':[Test_Accuracy],\n",
    "                    'TimeTaken':[time.time()-start]}\n",
    "    moddf = pd.DataFrame(model_metrics, columns=['Model','Accuracy','AUC',\n",
    "                                                 'F1_Score','Balanced_F1_Score',\n",
    "                                                 'Train_Accuracy','Test_Accuracy','TimeTaken'])\n",
    "    return moddf, pred_prob, var_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP (Multi-layer Perceptron classifier)Clf\n",
    "def mlp_clf(X_train, X_test, y_train, y_test, mdf):\n",
    "    start = time.time()\n",
    "    print('**MLP Classifier**')\n",
    "    mlp = MLPClassifier(random_state=1, max_iter=300)\n",
    "    mlp.fit(X_train,y_train)\n",
    "    predictions = mlp.predict(X_test)\n",
    "    Train_Accuracy = accuracy_score(y_train, mlp.predict(X_train))\n",
    "    Test_Accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\" Confusion matrix: \\n \", confusion_matrix(y_test, predictions))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions)\n",
    "    aucx = metrics.auc(fpr, tpr)\n",
    "    f1x = metrics.f1_score(y_test, predictions)\n",
    "    bal_f1scr = metrics.balanced_accuracy_score(y_test, predictions)\n",
    "    accuracyx = metrics.accuracy_score(y_test, predictions)\n",
    "    pred_prob = pd.concat([pd.DataFrame(mlp.predict_proba(mdf[X_train.columns])).reset_index(drop=True),mdf[pd.DataFrame(y_train).columns]], axis=1)\n",
    "    pred_prob = pd.concat([pred_prob.reset_index(drop=True),pd.DataFrame(mlp.predict(mdf[X_train.columns]))], axis=1)\n",
    "    pred_prob.columns = ['pred_prob_0','pred_prob_1', 'Actual', 'predicted']\n",
    "    var_imp = []\n",
    "    model_metrics = {'Model':['mlp_clf'],'Accuracy':[accuracyx],\n",
    "                     'AUC': [aucx], 'F1_Score':[f1x],'Balanced_F1_Score':[bal_f1scr],\n",
    "                    'Train_Accuracy':[Train_Accuracy], 'Test_Accuracy':[Test_Accuracy],\n",
    "                    'TimeTaken':[time.time()-start]}\n",
    "    moddf = pd.DataFrame(model_metrics, columns=['Model','Accuracy','AUC',\n",
    "                                                 'F1_Score','Balanced_F1_Score',\n",
    "                                                 'Train_Accuracy','Test_Accuracy','TimeTaken'])\n",
    "    return moddf, pred_prob, var_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearDiscriminantAnalysis\n",
    "def lda_clf(X_train, X_test, y_train, y_test, mdf):\n",
    "    start = time.time()\n",
    "    print('**Linear Discriminant Analysis**')\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(X_train,y_train)\n",
    "    predictions = lda.predict(X_test)\n",
    "    Train_Accuracy = accuracy_score(y_train, lda.predict(X_train))\n",
    "    Test_Accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\" Confusion matrix: \\n \", confusion_matrix(y_test, predictions))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions)\n",
    "    aucx = metrics.auc(fpr, tpr)\n",
    "    f1x = metrics.f1_score(y_test, predictions)\n",
    "    bal_f1scr = metrics.balanced_accuracy_score(y_test, predictions)\n",
    "    accuracyx = metrics.accuracy_score(y_test, predictions)\n",
    "    pred_prob = pd.concat([pd.DataFrame(lda.predict_proba(mdf[X_train.columns])).reset_index(drop=True),mdf[pd.DataFrame(y_train).columns]], axis=1)\n",
    "    pred_prob = pd.concat([pred_prob.reset_index(drop=True),pd.DataFrame(lda.predict(mdf[X_train.columns]))], axis=1)\n",
    "    pred_prob.columns = ['pred_prob_0','pred_prob_1', 'Actual', 'predicted']\n",
    "    var_imp = []\n",
    "    model_metrics = {'Model':['lda_clf'],'Accuracy':[accuracyx],\n",
    "                     'AUC': [aucx], 'F1_Score':[f1x],'Balanced_F1_Score':[bal_f1scr],\n",
    "                    'Train_Accuracy':[Train_Accuracy], 'Test_Accuracy':[Test_Accuracy],\n",
    "                    'TimeTaken':[time.time()-start]}\n",
    "    moddf = pd.DataFrame(model_metrics, columns=['Model','Accuracy','AUC',\n",
    "                                                 'F1_Score','Balanced_F1_Score',\n",
    "                                                 'Train_Accuracy','Test_Accuracy','TimeTaken'])\n",
    "    return moddf, pred_prob,var_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGDClassifier (stochastic gradient descent)\n",
    "def sgd_clf(X_train, X_test, y_train, y_test, mdf):\n",
    "    start = time.time()\n",
    "    print('**Stochastic Gradient Descent Clf**')\n",
    "    tuned_parameters = [{'loss': ['log', 'modified_huber']}] \n",
    "    ## Configuring grid search\n",
    "    clf = GridSearchCV(SGDClassifier(),\n",
    "                       tuned_parameters,\n",
    "                       cv=10,\n",
    "                       scoring='roc_auc')\n",
    "    clf.fit(X_train, y_train )\n",
    "    m = clf.best_params_\n",
    "    print(m)\n",
    "    ####\n",
    "    sgd = SGDClassifier(loss = m['loss'])\n",
    "    sgd.fit(X_train,y_train)\n",
    "    predictions = sgd.predict(X_test)\n",
    "    Train_Accuracy = accuracy_score(y_train, sgd.predict(X_train))\n",
    "    Test_Accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\" Confusion matrix: \\n \", confusion_matrix(y_test, predictions))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions)\n",
    "    aucx = metrics.auc(fpr, tpr)\n",
    "    f1x = metrics.f1_score(y_test, predictions)\n",
    "    bal_f1scr = metrics.balanced_accuracy_score(y_test, predictions)\n",
    "    accuracyx = metrics.accuracy_score(y_test, predictions)\n",
    "    pred_prob = pd.DataFrame(sgd.predict_proba(mdf[X_train.columns]))\n",
    "    pred_prob.columns = ['pred_prob_0','pred_prob_1']\n",
    "    pred_prob['predicted'] = (pred_prob['pred_prob_1'] > 0.65).astype('int')\n",
    "    var_imp = []\n",
    "    model_metrics = {'Model':['sgd_clf'],'Accuracy':[accuracyx],\n",
    "                     'AUC': [aucx], 'F1_Score':[f1x],'Balanced_F1_Score':[bal_f1scr],\n",
    "                    'Train_Accuracy':[Train_Accuracy], 'Test_Accuracy':[Test_Accuracy],\n",
    "                    'TimeTaken':[time.time()-start]}\n",
    "    moddf = pd.DataFrame(model_metrics, columns=['Model','Accuracy','AUC',\n",
    "                                                 'F1_Score','Balanced_F1_Score',\n",
    "                                                 'Train_Accuracy','Test_Accuracy','TimeTaken'])\n",
    "    return moddf, pred_prob,var_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering  - will vary based on context, project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Transaction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_excel(\"Jli_Surver_data_lapse.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = dft[dft['INVOICE_DATE']<'12/30/2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join With Survey Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.read_csv(\"survey_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_df = pd.read_csv(\"score1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs.merge(sat_df, how = 'left', left_on='SATISFACTION', right_on='find')\n",
    "dfs.rename(columns={'replace':'SATISFACTION_scr'},inplace=True)\n",
    "dfs = dfs.drop(['find'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_df = pd.read_csv(\"Score2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs.merge(return_df, how = 'left', left_on='OIL_CHANGE_RETURN', right_on='find')\n",
    "dfs.rename(columns={'replace':'OIL_CHANGE_RETURN_scr'},inplace=True)\n",
    "dfs = dfs.drop(['find'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs.merge(return_df, how = 'left', left_on='ROUTINE_MAINT_RETURN', right_on='find')\n",
    "dfs.rename(columns={'replace':'ROUTINE_MAINT_RETURN_scr'},inplace=True)\n",
    "dfs = dfs.drop(['find'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = pd.read_csv(\"gender_map.csv\")\n",
    "dfs = dfs.merge(gender_df, how = 'left', left_on='GENDER', right_on='find')\n",
    "dfs['GENDER'] = dfs['replace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs.loc[:,['INVOICE_NUMBER', 'SATISFACTION_scr',\n",
    "                 'OIL_CHANGE_RETURN_scr','ROUTINE_MAINT_RETURN_scr',\n",
    "                 'KNOWLEDGEABLE', 'FRIENDLY', 'QUALITY', 'TRUSTED_RECOMMENDATION',\n",
    "                 'TIMELY', 'GOOD_VALUE', 'WELL_TRAINED', 'EQUIPMENT',\n",
    "                 'GENDER', 'AGE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.sort_values(\"INVOICE_NUMBER\", inplace = True) \n",
    "dfs.drop_duplicates(subset =\"INVOICE_NUMBER\", keep = False, inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consolidaded Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section Covers Multiple aspects for data prep\n",
    "- Calculation of Lapse based on **Fixed Days**\n",
    "- Calculation of Lapse based on **Category Purchase Cycle**\n",
    "- Creation of **Dummy Variables** for Categorical data like Gender\n",
    "- **Removing Rows** where 50% of columns have missing values\n",
    "- **KNN Imputation** for missing values\n",
    "- **Upsampling** to factor for unbalanced dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dft.merge(dfs, how = 'left', on='INVOICE_NUMBER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid = 'leadkey'\n",
    "invoice_dt = 'INVOICE_DATE'\n",
    "inv_no = 'INVOICE_NUMBER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lapse using Avg. Category Purchase interval X 2\n",
    "df['previous_visit'] = df.sort_values(by=(invoice_dt)).groupby(uuid)[invoice_dt].shift(1)\n",
    "df['IPI'] = (df[invoice_dt] - df['previous_visit']).astype('timedelta64[D]')\n",
    "churn_factor = df['IPI'].mean() * 2\n",
    "df['lapse_IPI'] = (df['IPI'] > churn_factor).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tech Team if Lapse is to be defined based on Fixed No. of Days, use this variable input\n",
    "# Fixed No. of Days- lapse\n",
    "# Category Purchase interval - lapse_IPI\n",
    "lapse_days = 60 # Default valye is 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Churn- Last Invoice >X Days\n",
    "ndf = df.groupby(uuid)[invoice_dt].max()\n",
    "ndf = pd.DataFrame(ndf).reset_index()\n",
    "ndf.columns = [uuid,'lst_inv_dt']\n",
    "ndf['lapse'] = (ndf['lst_inv_dt'] + datetime.timedelta(days=lapse_days)) > max(df[invoice_dt])\n",
    "ndf['lapse'] = ndf['lapse'].astype(np.int8)\n",
    "ndf['key'] = ndf[uuid].map(str) + ndf['lst_inv_dt'].map(str)\n",
    "df['key'] = df[uuid].map(str) + df[invoice_dt].map(str)\n",
    "df=pd.merge(df,ndf.loc[:,['lapse','key']],how = 'left',on='key')\n",
    "df['lapse'] = df['lapse'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tech Team: This is input parameters  i.e. feature selection for the models\n",
    "x_input_feat = ['SATISFACTION_scr', 'OIL_CHANGE_RETURN_scr',\n",
    "                'KNOWLEDGEABLE', 'FRIENDLY', 'QUALITY',\n",
    "                'TRUSTED_RECOMMENDATION', 'TIMELY', 'GOOD_VALUE', 'WELL_TRAINED',\n",
    "                'EQUIPMENT', 'GENDER', 'AGE', 'TOTAL_INVOICE_AMOUNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future Enhancement: Build Alternative Model without using Survey Parameters when values are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dummy Variables - for Categorical Variables - converting to one-hot-encoding\n",
    "cat_vals = df[x_input_feat].select_dtypes(include='object').columns\n",
    "df_mod_op = pd.get_dummies(df[x_input_feat], columns = cat_vals, drop_first = True)\n",
    "x_input_feat_enc = df_mod_op.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SATISFACTION_scr', 'OIL_CHANGE_RETURN_scr', 'KNOWLEDGEABLE',\n",
       "       'FRIENDLY', 'QUALITY', 'TRUSTED_RECOMMENDATION', 'TIMELY', 'GOOD_VALUE',\n",
       "       'WELL_TRAINED', 'EQUIPMENT', 'TOTAL_INVOICE_AMOUNT', 'GENDER_Male',\n",
       "       'GENDER_Prefer Not to Answer', 'AGE_26-35', 'AGE_36-45', 'AGE_46-55',\n",
       "       'AGE_56-65', 'AGE_66+', 'AGE_Prefer not to answer',\n",
       "       'AGE_Prefiero no responder'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input_feat_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Rows which have >50% Of columns with missing values\n",
    "df_mod_op = pd.get_dummies(df, columns = cat_vals, drop_first = True)\n",
    "df_mod_op['na_check'] = (df_mod_op[x_input_feat_enc].isna().sum(axis=1) >  round(len(x_input_feat)/2)).astype('int')\n",
    "df_mod_op = df_mod_op.loc[df_mod_op['na_check']==0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tech Team: This is input parameter, whether lapse has to be based on Fixed No. of Days or\n",
    "# based in Inter Purchase Interval or Category Purchase Cycle (CPC)\n",
    "# Fixed Days columne is 'lapse', CPC based is 'lapse_IPI'\n",
    "y_var = 'lapse_IPI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Imputer for Missing Values (this is in the case where the missing values is less than 50% of columns)\n",
    "imputer = KNNImputer()\n",
    "df_mod_op2 = pd.DataFrame(imputer.fit_transform(df_mod_op[x_input_feat_enc], df_mod_op[y_var]))\n",
    "df_mod_op2.columns =x_input_feat_enc\n",
    "df_mod_op3 = pd.concat([df_mod_op.drop(x_input_feat_enc, axis=1).reset_index(drop=True),df_mod_op2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Upsampling\n",
    "ndf = up_sample_imbalanced(df_mod_op3, feature=y_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Factor Analysis Variable as model input\n",
    "X_Fact = FacterCluster(ndf[x_input_feat_enc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ndf[x_input_feat_enc], ndf[y_var], test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lapse_IPI'], dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Logistic Regression**\n",
      "Confusion matrix: \n",
      "  [[463 462]\n",
      " [447 478]]\n",
      "**Logistic Regression Cross Validation**\n",
      "Confusion matrix: \n",
      "  [[528 397]\n",
      " [458 467]]\n",
      "**Random Forest**\n",
      "Confusion matrix: \n",
      "  [[874  51]\n",
      " [132 793]]\n",
      "**Gradient Boosting Classifier**\n",
      "Confusion matrix: \n",
      "  [[894  31]\n",
      " [  0 925]]\n",
      "**Decision Tree Classification**\n",
      "Confusion matrix: \n",
      "  [[794 131]\n",
      " [502 423]]\n",
      "**KNN Classifier**\n",
      "Confusion matrix: \n",
      "  [[710 215]\n",
      " [  3 922]]\n",
      "**XG Boost Classifier**\n",
      " Confusion matrix: \n",
      "  [[694 231]\n",
      " [303 622]]\n",
      "**MLP Classifier**\n",
      " Confusion matrix: \n",
      "  [[409 516]\n",
      " [ 51 874]]\n",
      "**Linear Discriminant Analysis**\n",
      " Confusion matrix: \n",
      "  [[521 404]\n",
      " [456 469]]\n",
      "**Stochastic Gradient Descent Clf**\n",
      "{'loss': 'modified_huber'}\n",
      " Confusion matrix: \n",
      "  [[857  68]\n",
      " [863  62]]\n"
     ]
    }
   ],
   "source": [
    "model1, Logistic_Regression_proba,Logistic_Regression_varimp  = Logistic_Regression(X_train, X_test, y_train, y_test, ndf)\n",
    "model2,Logistic_Regression_CV_proba,Logistic_Regression_CV_varimp = Logistic_Regression_cv(X_train, X_test, y_train, y_test, ndf)\n",
    "model3, random_forest_clf_proba,random_forest_clf_varimp = random_forest(X_train, X_test, y_train, y_test, ndf)\n",
    "model4,gradient_boost_clf_proba,gradient_boost_clf_varimp = gradient_boost(X_train, X_test, y_train, y_test,ndf)\n",
    "model5,decision_tree_clf_proba,decision_tree_clf_varimp = decision_tree_clf(X_train, X_test, y_train, y_test,ndf)\n",
    "model6,knn_clf_proba,knn_clf_varimp = knn_clf(X_train, X_test, y_train, y_test,ndf)\n",
    "model7, xgb_clf_proba,xgb_clf_varimp= xgb_clf(X_train, X_test, y_train, y_test,ndf)\n",
    "model8, mlp_clf_proba,mlp_clf_varimp = mlp_clf(X_train, X_test, y_train, y_test,ndf)\n",
    "model9,lda_clf_proba,lda_clf_varimp = lda_clf(X_train, X_test, y_train, y_test,ndf)\n",
    "model10,sgd_clf_proba,sgd_clf_varimp = sgd_clf(X_train, X_test, y_train, y_test,ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_model = model1.append([model2,model3,model4,model5,model6,model7,model8,model9,model10]).reset_index()\n",
    "cons_model = pd.DataFrame(cons_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = [Logistic_Regression_proba,Logistic_Regression_CV_proba,random_forest_clf_proba,\n",
    "          gradient_boost_clf_proba,decision_tree_clf_proba,knn_clf_proba,xgb_clf_proba,\n",
    "         mlp_clf_proba,lda_clf_proba,sgd_clf_proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "varimp = [Logistic_Regression_varimp, Logistic_Regression_CV_varimp,random_forest_clf_varimp,\n",
    "          gradient_boost_clf_varimp,decision_tree_clf_varimp,knn_clf_varimp,xgb_clf_varimp,\n",
    "          mlp_clf_varimp ,lda_clf_varimp ,sgd_clf_varimp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Balanced_F1_Score</th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>TimeTaken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>gradient_boost_clf</td>\n",
       "      <td>0.983243</td>\n",
       "      <td>0.983243</td>\n",
       "      <td>0.983519</td>\n",
       "      <td>0.983243</td>\n",
       "      <td>0.996621</td>\n",
       "      <td>0.983243</td>\n",
       "      <td>13.278620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>random_forest_clf</td>\n",
       "      <td>0.901081</td>\n",
       "      <td>0.901081</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.901081</td>\n",
       "      <td>0.918897</td>\n",
       "      <td>0.901081</td>\n",
       "      <td>11.397573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>knn_clf</td>\n",
       "      <td>0.882162</td>\n",
       "      <td>0.882162</td>\n",
       "      <td>0.894277</td>\n",
       "      <td>0.882162</td>\n",
       "      <td>0.905380</td>\n",
       "      <td>0.882162</td>\n",
       "      <td>24.495088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>xgb_clf</td>\n",
       "      <td>0.711351</td>\n",
       "      <td>0.711351</td>\n",
       "      <td>0.699663</td>\n",
       "      <td>0.711351</td>\n",
       "      <td>0.739389</td>\n",
       "      <td>0.711351</td>\n",
       "      <td>1.622687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>mlp_clf</td>\n",
       "      <td>0.693514</td>\n",
       "      <td>0.693514</td>\n",
       "      <td>0.755076</td>\n",
       "      <td>0.693514</td>\n",
       "      <td>0.733712</td>\n",
       "      <td>0.693514</td>\n",
       "      <td>5.006267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy       AUC  F1_Score  Balanced_F1_Score  \\\n",
       "3  gradient_boost_clf  0.983243  0.983243  0.983519           0.983243   \n",
       "2   random_forest_clf  0.901081  0.901081  0.896552           0.901081   \n",
       "5             knn_clf  0.882162  0.882162  0.894277           0.882162   \n",
       "6             xgb_clf  0.711351  0.711351  0.699663           0.711351   \n",
       "7             mlp_clf  0.693514  0.693514  0.755076           0.693514   \n",
       "\n",
       "   Train_Accuracy  Test_Accuracy  TimeTaken  \n",
       "3        0.996621       0.983243  13.278620  \n",
       "2        0.918897       0.901081  11.397573  \n",
       "5        0.905380       0.882162  24.495088  \n",
       "6        0.739389       0.711351   1.622687  \n",
       "7        0.733712       0.693514   5.006267  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the model with best AUC Score\n",
    "best_mod = cons_model[(cons_model['Accuracy']>0.6) & (cons_model['AUC']>0.6) & (cons_model['F1_Score']>0.6)].drop('index',axis=1).sort_values(by=['AUC'],ascending=False)\n",
    "best_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_prob_0</th>\n",
       "      <th>pred_prob_1</th>\n",
       "      <th>Actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9243</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9244</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9245</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9246</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9247</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9248 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred_prob_0  pred_prob_1  Actual  predicted\n",
       "0        0.999955     0.000045       0          0\n",
       "1        0.999995     0.000005       0          0\n",
       "2        0.999974     0.000026       0          0\n",
       "3        0.999924     0.000076       0          0\n",
       "4        0.999998     0.000002       0          0\n",
       "...           ...          ...     ...        ...\n",
       "9243     0.000175     0.999825       1          1\n",
       "9244     0.000094     0.999906       1          1\n",
       "9245     0.000088     0.999912       1          1\n",
       "9246     0.000082     0.999918       1          1\n",
       "9247     0.000041     0.999959       1          1\n",
       "\n",
       "[9248 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Probabilities\n",
    "probas[best_mod.reset_index().iloc[0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link this back to the original dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Imp_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AGE_Prefiero no responder</td>\n",
       "      <td>0.875318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>GENDER_Prefer Not to Answer</td>\n",
       "      <td>1.024431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AGE_Prefer not to answer</td>\n",
       "      <td>1.225460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AGE_26-35</td>\n",
       "      <td>3.606281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AGE_36-45</td>\n",
       "      <td>5.288754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>AGE_46-55</td>\n",
       "      <td>5.609354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>SATISFACTION_scr</td>\n",
       "      <td>5.924238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>AGE_66+</td>\n",
       "      <td>6.335664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>OIL_CHANGE_RETURN_scr</td>\n",
       "      <td>6.596329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>AGE_56-65</td>\n",
       "      <td>6.755829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>GENDER_Male</td>\n",
       "      <td>9.103710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>FRIENDLY</td>\n",
       "      <td>15.911950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>QUALITY</td>\n",
       "      <td>16.160185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>TIMELY</td>\n",
       "      <td>21.399225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>KNOWLEDGEABLE</td>\n",
       "      <td>21.517824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>WELL_TRAINED</td>\n",
       "      <td>24.767626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>TRUSTED_RECOMMENDATION</td>\n",
       "      <td>26.303130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>GOOD_VALUE</td>\n",
       "      <td>27.799958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>EQUIPMENT</td>\n",
       "      <td>46.755091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>TOTAL_INVOICE_AMOUNT</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature   Imp_index\n",
       "0     AGE_Prefiero no responder    0.875318\n",
       "1   GENDER_Prefer Not to Answer    1.024431\n",
       "2      AGE_Prefer not to answer    1.225460\n",
       "3                     AGE_26-35    3.606281\n",
       "4                     AGE_36-45    5.288754\n",
       "5                     AGE_46-55    5.609354\n",
       "6              SATISFACTION_scr    5.924238\n",
       "7                       AGE_66+    6.335664\n",
       "8         OIL_CHANGE_RETURN_scr    6.596329\n",
       "9                     AGE_56-65    6.755829\n",
       "10                  GENDER_Male    9.103710\n",
       "11                     FRIENDLY   15.911950\n",
       "12                      QUALITY   16.160185\n",
       "13                       TIMELY   21.399225\n",
       "14                KNOWLEDGEABLE   21.517824\n",
       "15                 WELL_TRAINED   24.767626\n",
       "16       TRUSTED_RECOMMENDATION   26.303130\n",
       "17                   GOOD_VALUE   27.799958\n",
       "18                    EQUIPMENT   46.755091\n",
       "19         TOTAL_INVOICE_AMOUNT  100.000000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drivers of Churn - Variable Importance Index\n",
    "varimp[best_mod.reset_index().iloc[0,0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
